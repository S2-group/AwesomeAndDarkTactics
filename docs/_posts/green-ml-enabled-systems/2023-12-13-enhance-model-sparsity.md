---
layout: tactic

title:  "Enhance Model Sparsity"
tags: machine-learning model-optimization measured
t-sort: "Awesome Tactic"
t-type: "Architectural Tactic"
categories: green-ml-enabled-systems
t-description: "Enhancing sparsity of a machine learning model means reducing the number of model parameters or setting their values to zero. For example, weight sparsification involves identifying and removing unnecessary or less important weights in a neural network. Enhancing model sparsity decreases the complexity of the model and consequently reduces requirements for storage and memory. Therefore, it also results in lower power consumption."
t-participant: "Data Scientist"
t-artifact: "Machine Learning Algorithm"
t-context: "Machine Learning"
t-feature: 
t-intent: "Improve energy efficiency by removing unnecessary or less important weights in neural networks"
t-targetQA: "Energy Efficiency"
t-relatedQA: "Accuracy"
t-measuredimpact: "Removing unnecessary or less important weights in neural networks lowers energy consumption."
t-source: "Xiangyu Yang, Sheng Hua, Yuanming Shi, Hao Wang, Jun Zhang, and Khaled B. Letaief. 2020. Sparse Optimization for Green Edge AI Inference. Journal of Communications and Information Networks 5, 1 (2020), 1â€“15."
t-source-doi: "https://doi.org/10.23919/JCIN.2020.9055106"
t-diagram: "enhance-model-sparsity.png"
---