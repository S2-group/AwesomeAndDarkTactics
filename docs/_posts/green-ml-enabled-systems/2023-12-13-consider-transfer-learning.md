---
layout: tactic

title: "Consider Transfer Learning"
tags: machine-learning model-optimization
t-sort: "Awesome Tactic"
t-type: "Architectural Tactic"
categories: green-ml-enabled-systems
t-description: "Transfer learning means using knowledge gained from one task (a pre-trained model) and applying it to another similar task. This is feasible only if there is an existing pre-trained model available for use. The absence of or reduction in the model training effort results in savings in energy consumption."
t-participant: "Data Scientist"
t-artifact: "Machine Learning Algorithm"
t-context: "Machine Learning"
t-feature: "Neural Networks"
t-intent: "Improve energy efficiency by using transfer learning with pre-trained models whenever feasible"
t-targetQA: "Energy Efficiency"
t-relatedQA: 
t-measuredimpact: 
t-source: "Nitthilan Kanappan Jayakodi, Syrine Belakaria, Aryan Deshwal, and Janardhan Rao Doppa. 2020. Design and Optimization Of Energy-Accuracy Tradeoff Networks For Mobile Platforms Via Pretrained Deep Models. ACM Transactions on Embedded Computing Systems (TECS) 19, 1 (2020), 1–24. [DOI](https://doi.org/10.1145/3366636); Shriram Shanbhag, Sridhar Chimalakonda, Vibhu Saujanya Sharma, and Vikrant Kaulgud. 2022. Towards a Catalog of Energy Patterns in Deep Learning Development. In Proceedings of the International Conference on Evaluation and Assessment in Software Engineering 2022. 150–159. [DOI](https://doi.org/10.1145/3530019.3530035)"
t-source-doi: 
t-diagram: "consider-transfer-learning.png"
---